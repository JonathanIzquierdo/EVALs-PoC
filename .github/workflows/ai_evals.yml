name: AI Evals CI

on:
  workflow_call:
    inputs:
      api_mode:
        description: 'Run in API mode (true) or direct mode (false)'
        required: false
        type: string
        default: 'true'
  
  workflow_dispatch:
    inputs:
      api_mode:
        description: 'Run in API mode (true) or direct mode (false)'
        required: true
        default: 'true'
        type: choice
        options:
          - 'true'
          - 'false'

jobs:
  evaluate:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Determine evaluation mode
      id: mode
      run: |
        echo "api_mode=${{ inputs.api_mode }}" >> $GITHUB_OUTPUT
        if [ "${{ inputs.api_mode }}" == "true" ]; then
          echo "üì° Running in API mode"
        else
          echo "üíª Running in direct mode"
        fi
    
    - name: Start API server (if API mode)
      if: steps.mode.outputs.api_mode == 'true'
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        OPENAI_ENDPOINT: ${{ secrets.OPENAI_ENDPOINT }}
        OPENAI_DEPLOYMENT_ID: ${{ secrets.OPENAI_DEPLOYMENT_ID }}
        OPENAI_API_VERSION: ${{ secrets.OPENAI_API_VERSION }}
        OPENAI_TEMPERATURE: "0.9"
      run: |
        echo "Starting API server for evaluation..."
        nohup python app.py > api.log 2>&1 &
        echo $! > api.pid
        sleep 15
        
    - name: Health check (if API mode)
      if: steps.mode.outputs.api_mode == 'true'
      run: |
        echo "Checking API health..."
        max_attempts=10
        attempt=0
        while [ $attempt -lt $max_attempts ]; do
          if curl -f http://localhost:8000/health; then
            echo "‚úÖ API is healthy and ready for evaluation"
            exit 0
          fi
          echo "Waiting for API... ($((attempt+1))/$max_attempts)"
          sleep 3
          attempt=$((attempt+1))
        done
        echo "‚ùå API health check failed"
        echo "=== API Logs ==="
        cat api.log
        exit 1
        
    - name: Run AI Evaluations
      env:
        USE_API_MODE: ${{ steps.mode.outputs.api_mode }}
        API_BASE_URL: http://localhost:8000
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        OPENAI_ENDPOINT: ${{ secrets.OPENAI_ENDPOINT }}
        OPENAI_DEPLOYMENT_ID: ${{ secrets.OPENAI_DEPLOYMENT_ID }}
        OPENAI_API_VERSION: ${{ secrets.OPENAI_API_VERSION }}
        OPENAI_TEMPERATURE: "0.9"
      run: |
        echo "üöÄ Running AI evaluations..."
        python run_ai_evals.py
        
    - name: Upload evaluation results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: evaluation-results
        path: |
          *.log
        retention-days: 30
    
    - name: Stop API server
      if: always() && steps.mode.outputs.api_mode == 'true'
      run: |
        if [ -f api.pid ]; then
          echo "Stopping API server..."
          kill $(cat api.pid) || true
          rm api.pid
          echo "API server stopped"
        fi
        
    - name: Show API logs on failure
      if: failure() && steps.mode.outputs.api_mode == 'true'
      run: |
        echo "=== API Server Logs ==="
        cat api.log || echo "No logs available"
        
    - name: Upload results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: ai-evals-report
        path: |
          test_cases.json
